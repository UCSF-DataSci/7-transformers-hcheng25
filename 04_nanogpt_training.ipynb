{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f4c463b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e11541bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d96f9",
   "metadata": {},
   "source": [
    "## 1. Exploring the Synthetic Mention Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01bc5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore the Synthetic Mention Corpora for Disease Entity Recognition\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs('data/synthetic_mentions', exist_ok=True)\n",
    "\n",
    "# Function to download the dataset\n",
    "def download_synthetic_mentions():\n",
    "    \"\"\"\n",
    "    Download the Synthetic Mention Corpora for Disease Entity Recognition\n",
    "    \n",
    "    Note: You need to manually download this dataset from PhysioNet:\n",
    "    https://physionet.org/content/synthetic-mention-corpora/\n",
    "    \n",
    "    After downloading, place the files in the data/synthetic_mentions directory\n",
    "    \"\"\"\n",
    "    mentions_data_path = 'data/synthetic_mentions/disease_mentions.json'\n",
    "    \n",
    "    if os.path.exists(mentions_data_path):\n",
    "        print(f\"Loading Synthetic Mention Corpora from {mentions_data_path}\")\n",
    "        with open(mentions_data_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Synthetic Mention Corpora not found at {mentions_data_path}\")\n",
    "        print(\"Please download the dataset from PhysioNet:\")\n",
    "        print(\"https://physionet.org/content/synthetic-mention-corpora/\")\n",
    "        print(\"After downloading, place the files in the data/synthetic_mentions directory\")\n",
    "        return None\n",
    "\n",
    "# Try to load the dataset\n",
    "mentions_data = download_synthetic_mentions()\n",
    "\n",
    "# If the dataset is loaded successfully, convert to text for training\n",
    "if mentions_data is not None:\n",
    "    # Extract mentions and combine into a single text\n",
    "    mentions_text = \"\"\n",
    "    for item in mentions_data[:1000]:  # Start with a subset for exploration\n",
    "        if \"mention\" in item:\n",
    "            mentions_text += item[\"mention\"] + \"\\n\"\n",
    "        if \"context\" in item:\n",
    "            mentions_text += item[\"context\"] + \"\\n\\n\"\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(f\"Total characters: {len(mentions_text)}\")\n",
    "    print(f\"Total words: {len(mentions_text.split())}\")\n",
    "    print(f\"Total lines: {len(mentions_text.splitlines())}\")\n",
    "    \n",
    "    # Print the first few lines\n",
    "    print(\"\\nFirst few lines:\")\n",
    "    for i, line in enumerate(mentions_text.splitlines()[:5]):\n",
    "        print(f\"{i+1}: {line}\")\n",
    "    \n",
    "    # Check if the data is suitable for training\n",
    "    if len(mentions_text) < 100000:  # Less than 100KB\n",
    "        print(\"\\nWarning: The extracted text might be too small for effective training.\")\n",
    "        print(\"Consider using more entries from the dataset.\")\n",
    "    else:\n",
    "        print(\"\\nThe extracted text seems suitable for training.\")\n",
    "    \n",
    "    # Save the combined text for training\n",
    "    with open('data/processed/mentions_text.txt', 'w') as f:\n",
    "        f.write(mentions_text)\n",
    "    print(\"Saved combined text to data/processed/mentions_text.txt\")\n",
    "else:\n",
    "    # Fallback to open_db.txt if the dataset is not available\n",
    "    print(\"Falling back to open_db.txt for training\")\n",
    "    \n",
    "    def read_open_db():\n",
    "        \"\"\"Read the open database text file\"\"\"\n",
    "        with open('open_db.txt', 'r') as f:\n",
    "            text = f.read()\n",
    "        return text\n",
    "    \n",
    "    # Read the open database text\n",
    "    mentions_text = read_open_db()\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(f\"Total characters: {len(mentions_text)}\")\n",
    "    print(f\"Total words: {len(mentions_text.split())}\")\n",
    "    print(f\"Total lines: {len(mentions_text.splitlines())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
